---
title: Yuxiang's Personal Website
name: Yuxiang Wei
date: 08/18/2024
photo_path: ./static/images/yuxiang.jpg
email_school: ywei40@illinois.edu
email_personal: yuxiang630.wei@gmail.com
github_id: UniverseFly
github_url: https://github.com/UniverseFly
twitter_id: YuxiangWei9
twitter_url: https://twitter.com/YuxiangWei9
google_scholar_url: https://scholar.google.com/citations?user=Clrvw6kAAAAJ&hl=en&oi=ao
bibliography: ./static/bib.bib
nocite: |
  @*
---

## About

I am a PhD candidate at UIUC CS, advised by [Lingming Zhang](https://lingming.cs.illinois.edu). I am also a part-time researcher at [Meta FAIR](https://ai.meta.com/), working with [Sida Wang](https://www.sidaw.xyz), [Rishabh Singh](https://rishabhmit.bitbucket.io), [Daniel Fried](https://dpfried.github.io), and [Gabriel Synnaeve](https://scholar.google.com/citations?user=wN9rBkcAAAAJ&hl=en).

I work on **training LLMs for code and software**, with experience and published results in pretraining, midtraining, and posttraining via synthetic data and reinforcement learning.

**Researh impact:** I lead [Magicoder](https://github.com/ise-uiuc/magicoder) (ICML'24) and [SelfCodeAlign](https://github.com/bigcode-project/selfcodealign) (NeurIPS'24), projects with **400k+ downloads and 2.2k+ GitHub stars**. They have been adopted by leading industry language models, including **Meta Llama 3**, **Google CodeGemma**, and **IBM Granite code models**.

## News

- Feb 2025: We released [SWE-RL](https://github.com/facebookresearch/swe-rl), the first approach to scale reinforcement learning based LLM reasoning for real-world software engineering.
- Sep 2024: [SelfCodeAlign](https://github.com/bigcode-project/starcoder2-self-align) got accepted to [NeurIPS'24](https://neurips.cc/Conferences/2024)!
- May 2024: [üé©Magicoder](https://github.com/ise-uiuc/magicoder) (**2k** ‚≠êÔ∏è on GitHub) got accepted to [ICML'24](https://icml.cc/Conferences/2024)!

<!-- - May 2024: We released [StarCoder2-Instruct](https://huggingface.co/blog/sc2-instruct): the first fully transparent and permissive self-alignment for code generation.
- Feb 2024: [StarCoder2 released](https://huggingface.co/blog/starcoder2). So proud to be part of the team! -->


## Publications

::: {#refs}
:::

## Awards and Honors

- Feb 2025, [Repilot](https://github.com/ise-uiuc/Repilot) (FSE'23) recognized by CACM Research Highlights.
- Sep 2024, Selected Proposal, Amazon Trusted AI Challenge ($250,000)
- Jun 2024, [OpenAI Researcher Access Program](https://openai.com/form/researcher-access-program/) ($5,000)
- Oct 2023, NSF Student Travel Award ($1,800)
- Oct 2023, ACM SIGSOFT CAPS Award ($400)

## Services

- Organizing Committee:
  [LLM4Code'25](https://llm4code.github.io),
  [LLM4Code'24](https://llm4code.github.io/2024).
- Reviewer:
  [ICLR'25](https://iclr.cc/Conferences/2025),
  [TSE](https://www.computer.org/csdl/journal/ts),
  [NeurIPS'24](https://neurips.cc/Conferences/2024),
  [MIPR'24](https://sites.google.com/view/mipr2024),
  [GLSVLSI'24](https://www.glsvlsi.org),
  [SynData4CV@CVPR'24](https://syndata4cv.github.io/index.html),
  [R2-FM@ICLR'24](https://iclr-r2fm.github.io).
- Artifact Evaluation Committee: [ISSTA'24](https://2024.issta.org/committee/issta-2024-artifact-evaluation-artifact-evaluation-committee), [PLDI'24](https://pldi24.sigplan.org/committee/pldi-2024-pldi-research-artifacts-artifact-evaluation-committee), [CCS'23](https://www.sigsac.org/ccs/CCS2023/call-for-artifacts.html).

## Invited Talks

- Sep 2024, [CS6501](https://wenxiwang.github.io/CS6501-016.html) @ University of Virginia: Guest lecture on language models.
- Mar 2024, [Meta FAIR (Code Llama)](https://ai.meta.com/research/): Discussions on Magicoder and Its Extensions
- Jan 2024, [Snowflake GenAI (Copilot)](https://www.snowflake.com/blog/use-ai-snowflake-cortex/): Magicoder: Source Code Is All You Need [[Slides](./static/documents/Magicoder-Talk-Snowflake.pdf)].
- Oct 2023, Kwai Inc.: Fusing Large Language Models with Completion Engines for Code Generation.
- Apr 2023, Uber Program Analysis Group: Combining Large Language Models with Symbolic Methods.
